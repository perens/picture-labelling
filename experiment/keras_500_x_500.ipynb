{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of PictureLabelling_Kera_sander.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X-GtZsJvtdY"
      },
      "source": [
        "from fastai.vision import *\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "import tensorflow\r\n",
        "from tensorflow import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras import backend as k\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from urllib.request import urlretrieve\r\n",
        "import csv\r\n",
        "from keras import backend as K\r\n",
        "from PIL import ImageFile, Image\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puLHCyAqwR6H"
      },
      "source": [
        "response = json.loads(requests.get(\"http://arnelism.com/realestate/labelled/files.json\").text)\r\n",
        "response_documents = json.loads(requests.get(\"https://raw.githubusercontent.com/perens/picture-labelling/main/src/resources/dokumendi_blanketid.json\").text)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNipxn1DGOpc"
      },
      "source": [
        "!mkdir train\r\n",
        "!mkdir train/facade0\r\n",
        "!mkdir train/interior0\r\n",
        "!mkdir train/document0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dYjQ39TGRmM"
      },
      "source": [
        "facades = [url for url in response if \"facade\" in url]\r\n",
        "interiors = [url for url in response if \"interior\" in url]\r\n",
        "documents = [url for url in response_documents]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsxtGcVlLjJa",
        "outputId": "667c9c54-9ea2-4c3b-bd85-18bd3dc87d24"
      },
      "source": [
        "print(len(facades))\r\n",
        "fadaces_train = facades[0:500]\r\n",
        "facades_valid = facades[500:len(facades)]\r\n",
        "print(len(interiors))\r\n",
        "interiors_train = interiors[0:400]\r\n",
        "interiors_valid = interiors[400:len(interiors)]\r\n",
        "print(len(documents))\r\n",
        "documents_train = documents[0:200]\r\n",
        "documents_valid = documents[200:len(documents)]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "562\n",
            "473\n",
            "226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea2y7b3nGWIq"
      },
      "source": [
        "f = open(\"facades_train.csv\", \"a\")\r\n",
        "for url in fadaces_train:\r\n",
        "  f.write(url + \"\\n\")\r\n",
        "f.close()\r\n",
        "\r\n",
        "f = open(\"interiors_train.csv\", \"a\")\r\n",
        "for url in interiors_train:\r\n",
        "  f.write(url + \"\\n\")\r\n",
        "f.close()\r\n",
        "\r\n",
        "f = open(\"documents_train.csv\", \"a\")\r\n",
        "for url in documents_train:\r\n",
        "  f.write(url + \"\\n\")\r\n",
        "f.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oTeMDoUMW4q"
      },
      "source": [
        "f = open(\"facades_valid.csv\", \"a\")\r\n",
        "for url in facades_valid:\r\n",
        "  f.write(url + \"\\n\")\r\n",
        "f.close()\r\n",
        "\r\n",
        "f = open(\"interiors_valid.csv\", \"a\")\r\n",
        "for url in interiors_valid:\r\n",
        "  f.write(url + \"\\n\")\r\n",
        "f.close()\r\n",
        "\r\n",
        "f = open(\"documents_valid.csv\", \"a\")\r\n",
        "for url in documents_valid:\r\n",
        "  f.write(url + \"\\n\")\r\n",
        "f.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lWdQqaBiGYNq",
        "outputId": "7ef95bb1-710c-495a-99ad-78b8099016bd"
      },
      "source": [
        "\"\"\"with open ('interiors.csv') as images:\r\n",
        "    images = csv.reader(images)\r\n",
        "    img_count = 1  # start at 1\r\n",
        "    for image in images:\r\n",
        "        urlretrieve(image[0],'train/interior0/image_{0}.jpg'.format(img_count)) # string formatting inserting count \r\n",
        "        img_count += 1 # increase count for each image.\r\n",
        "print(\"Interiors saved!\")\r\n",
        "\r\n",
        "with open ('facades.csv') as images:\r\n",
        "    images = csv.reader(images)\r\n",
        "    img_count = 1  # start at 1\r\n",
        "    for image in images:\r\n",
        "        urlretrieve(image[0],'train/facade0/image_{0}.jpg'.format(img_count)) # string formatting inserting count \r\n",
        "        img_count += 1 # increase count for each image.\r\n",
        "print(\"Facades saved!\")\r\n",
        "      \r\n",
        "with open ('documents.csv') as images:\r\n",
        "    images = csv.reader(images)\r\n",
        "    img_count = 1  # start at 1\r\n",
        "    for image in images:\r\n",
        "        urlretrieve(image[0],'train/document0/image_{0}.jpg'.format(img_count)) # string formatting inserting count \r\n",
        "        img_count += 1 # increase count for each image.\r\n",
        "print(\"Documents saved!\")\"\"\"\r\n",
        "\r\n",
        "download_images(\"facades_train.csv\", 'train/facade0', max_pics=1000) \r\n",
        "download_images(\"interiors_train.csv\", 'train/interior0', max_pics=1000)\r\n",
        "download_images(\"documents_train.csv\", 'train/document0', max_pics=1000)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "NZv3lbFFGbxv",
        "outputId": "61c29b6c-a66b-44ce-8160-720aa6c86986"
      },
      "source": [
        "classes = [\"facade0\", \"interior0\", \"document0\"]\r\n",
        "path = \"train\"\r\n",
        "for c in classes:\r\n",
        "    print(c)\r\n",
        "    verify_images(f\"train/{c}\", delete=True, max_size=1000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "facade0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interior0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "document0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UsYgUPwGsUA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "50d748ad-476f-457d-dccd-ded5ea93fb43"
      },
      "source": [
        "\"\"\"for directory in [\"train/facade0\", \"train/interior0\", \"train/document0\"]:\r\n",
        "  print(directory)\r\n",
        "  for entry in os.scandir(directory):\r\n",
        "    if entry.path.endswith(\".jpg\") and entry.is_file():\r\n",
        "      print(\".\", end=\" \")\r\n",
        "      img = Image.open(entry.path)\r\n",
        "      path_parts = img.filename.split('/')      \r\n",
        "      label = path_parts[1][:-1]\r\n",
        "      degrees = [90, 180, 270]\r\n",
        "      filename = path_parts[2]\r\n",
        "      for d in degrees:\r\n",
        "          rotate_img = img.rotate(d)\r\n",
        "          rot_name =  f\"train/{label}{d}/{filename}\"\r\n",
        "          rotate_img.save(rot_name)\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'for directory in [\"train/facade0\", \"train/interior0\", \"train/document0\"]:\\n  print(directory)\\n  for entry in os.scandir(directory):\\n    if entry.path.endswith(\".jpg\") and entry.is_file():\\n      print(\".\", end=\" \")\\n      img = Image.open(entry.path)\\n      path_parts = img.filename.split(\\'/\\')      \\n      label = path_parts[1][:-1]\\n      degrees = [90, 180, 270]\\n      filename = path_parts[2]\\n      for d in degrees:\\n          rotate_img = img.rotate(d)\\n          rot_name =  f\"train/{label}{d}/{filename}\"\\n          rotate_img.save(rot_name)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_hs5iIMHLaS"
      },
      "source": [
        "!mkdir validation\r\n",
        "!mkdir validation/facade0\r\n",
        "!mkdir validation/interior0\r\n",
        "!mkdir validation/document0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PWWnfyjFGydB",
        "outputId": "6cc688e5-dec3-482a-f0b5-43d98c6c3f34"
      },
      "source": [
        "download_images(\"facades_valid.csv\", 'validation/facade0', max_pics=100)\r\n",
        "download_images(\"interiors_valid.csv\", 'validation/interior0', max_pics=100)\r\n",
        "download_images(\"documents_valid.csv\", 'validation/document0', max_pics=100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "nhv8P9dLHyHR",
        "outputId": "b6f626b0-4769-4f69-dd28-5f036f95d361"
      },
      "source": [
        "classes = [\"facade0\", \"interior0\", \"document0\"]\r\n",
        "path = \"validation\"\r\n",
        "for c in classes:\r\n",
        "    print(c)\r\n",
        "    verify_images(f\"validation/{c}\", delete=True, max_size=1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "facade0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "interior0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "document0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCdKyaE4u6aT",
        "outputId": "c00df566-61b7-4f42-c283-940a7193d17d"
      },
      "source": [
        "!pip install keras_applications"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nz6pdCznZwy"
      },
      "source": [
        "# https://github.com/keras-team/keras-contrib\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"ResNet v1, v2, and segmentation models for Keras.\r\n",
        "# Reference\r\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\r\n",
        "- [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)\r\n",
        "Reference material for extended functionality:\r\n",
        "- [ResNeXt](https://arxiv.org/abs/1611.05431) for Tiny ImageNet support.\r\n",
        "- [Dilated Residual Networks](https://arxiv.org/pdf/1705.09914) for segmentation support\r\n",
        "- [Deep Residual Learning for Instrument Segmentation in\r\n",
        "   Robotic Surgery](https://arxiv.org/abs/1703.08580)\r\n",
        "  for segmentation support.\r\n",
        "Implementation Adapted from: github.com/raghakot/keras-resnet\r\n",
        "\"\"\"  # pylint: disable=E501\r\n",
        "from __future__ import division\r\n",
        "\r\n",
        "import six\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers import Activation\r\n",
        "from keras.layers import Reshape\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras.layers import GlobalMaxPooling2D\r\n",
        "from keras.layers import GlobalAveragePooling2D\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers.merge import add\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras import backend as K\r\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\r\n",
        "\r\n",
        "\r\n",
        "def _bn_relu(x, bn_name=None, relu_name=None):\r\n",
        "    \"\"\"Helper to build a BN -> relu block\r\n",
        "    \"\"\"\r\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS, name=bn_name)(x)\r\n",
        "    return Activation(\"relu\", name=relu_name)(norm)\r\n",
        "\r\n",
        "\r\n",
        "def _conv_bn_relu(**conv_params):\r\n",
        "    \"\"\"Helper to build a conv -> BN -> relu residual unit activation function.\r\n",
        "       This is the original ResNet v1 scheme in https://arxiv.org/abs/1512.03385\r\n",
        "    \"\"\"\r\n",
        "    filters = conv_params[\"filters\"]\r\n",
        "    kernel_size = conv_params[\"kernel_size\"]\r\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\r\n",
        "    dilation_rate = conv_params.setdefault(\"dilation_rate\", (1, 1))\r\n",
        "    conv_name = conv_params.setdefault(\"conv_name\", None)\r\n",
        "    bn_name = conv_params.setdefault(\"bn_name\", None)\r\n",
        "    relu_name = conv_params.setdefault(\"relu_name\", None)\r\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\r\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\r\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\r\n",
        "\r\n",
        "    def f(x):\r\n",
        "        x = Conv2D(filters=filters, kernel_size=kernel_size,\r\n",
        "                   strides=strides, padding=padding,\r\n",
        "                   dilation_rate=dilation_rate,\r\n",
        "                   kernel_initializer=kernel_initializer,\r\n",
        "                   kernel_regularizer=kernel_regularizer,\r\n",
        "                   name=conv_name)(x)\r\n",
        "        return _bn_relu(x, bn_name=bn_name, relu_name=relu_name)\r\n",
        "\r\n",
        "    return f\r\n",
        "\r\n",
        "\r\n",
        "def _bn_relu_conv(**conv_params):\r\n",
        "    \"\"\"Helper to build a BN -> relu -> conv residual unit with full pre-activation\r\n",
        "    function. This is the ResNet v2 scheme proposed in\r\n",
        "    http://arxiv.org/pdf/1603.05027v2.pdf\r\n",
        "    \"\"\"\r\n",
        "    filters = conv_params[\"filters\"]\r\n",
        "    kernel_size = conv_params[\"kernel_size\"]\r\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\r\n",
        "    dilation_rate = conv_params.setdefault(\"dilation_rate\", (1, 1))\r\n",
        "    conv_name = conv_params.setdefault(\"conv_name\", None)\r\n",
        "    bn_name = conv_params.setdefault(\"bn_name\", None)\r\n",
        "    relu_name = conv_params.setdefault(\"relu_name\", None)\r\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\r\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\r\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\r\n",
        "\r\n",
        "    def f(x):\r\n",
        "        activation = _bn_relu(x, bn_name=bn_name, relu_name=relu_name)\r\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\r\n",
        "                      strides=strides, padding=padding,\r\n",
        "                      dilation_rate=dilation_rate,\r\n",
        "                      kernel_initializer=kernel_initializer,\r\n",
        "                      kernel_regularizer=kernel_regularizer,\r\n",
        "                      name=conv_name)(activation)\r\n",
        "\r\n",
        "    return f\r\n",
        "\r\n",
        "\r\n",
        "def _shortcut(input_feature, residual, conv_name_base=None, bn_name_base=None):\r\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\r\n",
        "    \"\"\"\r\n",
        "    # Expand channels of shortcut to match residual.\r\n",
        "    # Stride appropriately to match residual (width, height)\r\n",
        "    # Should be int if network architecture is correctly configured.\r\n",
        "    input_shape = K.int_shape(input_feature)\r\n",
        "    residual_shape = K.int_shape(residual)\r\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\r\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\r\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\r\n",
        "\r\n",
        "    shortcut = input_feature\r\n",
        "    # 1 X 1 conv if shape is different. Else identity.\r\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\r\n",
        "        print('reshaping via a convolution...')\r\n",
        "        if conv_name_base is not None:\r\n",
        "            conv_name_base = conv_name_base + '1'\r\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\r\n",
        "                          kernel_size=(1, 1),\r\n",
        "                          strides=(stride_width, stride_height),\r\n",
        "                          padding=\"valid\",\r\n",
        "                          kernel_initializer=\"he_normal\",\r\n",
        "                          kernel_regularizer=l2(0.0001),\r\n",
        "                          name=conv_name_base)(input_feature)\r\n",
        "        if bn_name_base is not None:\r\n",
        "            bn_name_base = bn_name_base + '1'\r\n",
        "        shortcut = BatchNormalization(axis=CHANNEL_AXIS,\r\n",
        "                                      name=bn_name_base)(shortcut)\r\n",
        "\r\n",
        "    return add([shortcut, residual])\r\n",
        "\r\n",
        "\r\n",
        "def _residual_block(block_function, filters, blocks, stage,\r\n",
        "                    transition_strides=None, transition_dilation_rates=None,\r\n",
        "                    dilation_rates=None, is_first_layer=False, dropout=None,\r\n",
        "                    residual_unit=_bn_relu_conv):\r\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\r\n",
        "       stage: integer, current stage label, used for generating layer names\r\n",
        "       blocks: number of blocks 'a','b'..., current block label, used for generating\r\n",
        "            layer names\r\n",
        "       transition_strides: a list of tuples for the strides of each transition\r\n",
        "       transition_dilation_rates: a list of tuples for the dilation rate of each\r\n",
        "            transition\r\n",
        "    \"\"\"\r\n",
        "    if transition_dilation_rates is None:\r\n",
        "        transition_dilation_rates = [(1, 1)] * blocks\r\n",
        "    if transition_strides is None:\r\n",
        "        transition_strides = [(1, 1)] * blocks\r\n",
        "    if dilation_rates is None:\r\n",
        "        dilation_rates = [1] * blocks\r\n",
        "\r\n",
        "    def f(x):\r\n",
        "        for i in range(blocks):\r\n",
        "            is_first_block = is_first_layer and i == 0\r\n",
        "            x = block_function(filters=filters, stage=stage, block=i,\r\n",
        "                               transition_strides=transition_strides[i],\r\n",
        "                               dilation_rate=dilation_rates[i],\r\n",
        "                               is_first_block_of_first_layer=is_first_block,\r\n",
        "                               dropout=dropout,\r\n",
        "                               residual_unit=residual_unit)(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    return f\r\n",
        "\r\n",
        "\r\n",
        "def _block_name_base(stage, block):\r\n",
        "    \"\"\"Get the convolution name base and batch normalization name base defined by\r\n",
        "    stage and block.\r\n",
        "    If there are less than 26 blocks they will be labeled 'a', 'b', 'c' to match the\r\n",
        "    paper and keras and beyond 26 blocks they will simply be numbered.\r\n",
        "    \"\"\"\r\n",
        "    if block < 27:\r\n",
        "        block = '%c' % (block + 97)  # 97 is the ascii number for lowercase 'a'\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "    return conv_name_base, bn_name_base\r\n",
        "\r\n",
        "\r\n",
        "def basic_block(filters, stage, block, transition_strides=(1, 1),\r\n",
        "                dilation_rate=(1, 1), is_first_block_of_first_layer=False, dropout=None,\r\n",
        "                residual_unit=_bn_relu_conv):\r\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\r\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\r\n",
        "    \"\"\"\r\n",
        "    def f(input_features):\r\n",
        "        conv_name_base, bn_name_base = _block_name_base(stage, block)\r\n",
        "        if is_first_block_of_first_layer:\r\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\r\n",
        "            x = Conv2D(filters=filters, kernel_size=(3, 3),\r\n",
        "                       strides=transition_strides,\r\n",
        "                       dilation_rate=dilation_rate,\r\n",
        "                       padding=\"same\",\r\n",
        "                       kernel_initializer=\"he_normal\",\r\n",
        "                       kernel_regularizer=l2(1e-4),\r\n",
        "                       name=conv_name_base + '2a')(input_features)\r\n",
        "        else:\r\n",
        "            x = residual_unit(filters=filters, kernel_size=(3, 3),\r\n",
        "                              strides=transition_strides,\r\n",
        "                              dilation_rate=dilation_rate,\r\n",
        "                              conv_name_base=conv_name_base + '2a',\r\n",
        "                              bn_name_base=bn_name_base + '2a')(input_features)\r\n",
        "\r\n",
        "        if dropout is not None:\r\n",
        "            x = Dropout(dropout)(x)\r\n",
        "\r\n",
        "        x = residual_unit(filters=filters, kernel_size=(3, 3),\r\n",
        "                          conv_name_base=conv_name_base + '2b',\r\n",
        "                          bn_name_base=bn_name_base + '2b')(x)\r\n",
        "\r\n",
        "        return _shortcut(input_features, x)\r\n",
        "\r\n",
        "    return f\r\n",
        "\r\n",
        "\r\n",
        "def bottleneck(filters, stage, block, transition_strides=(1, 1),\r\n",
        "               dilation_rate=(1, 1), is_first_block_of_first_layer=False, dropout=None,\r\n",
        "               residual_unit=_bn_relu_conv):\r\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\r\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\r\n",
        "    Returns:\r\n",
        "        A final conv layer of filters * 4\r\n",
        "    \"\"\"\r\n",
        "    def f(input_feature):\r\n",
        "        conv_name_base, bn_name_base = _block_name_base(stage, block)\r\n",
        "        if is_first_block_of_first_layer:\r\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\r\n",
        "            x = Conv2D(filters=filters, kernel_size=(1, 1),\r\n",
        "                       strides=transition_strides,\r\n",
        "                       dilation_rate=dilation_rate,\r\n",
        "                       padding=\"same\",\r\n",
        "                       kernel_initializer=\"he_normal\",\r\n",
        "                       kernel_regularizer=l2(1e-4),\r\n",
        "                       name=conv_name_base + '2a')(input_feature)\r\n",
        "        else:\r\n",
        "            x = residual_unit(filters=filters, kernel_size=(1, 1),\r\n",
        "                              strides=transition_strides,\r\n",
        "                              dilation_rate=dilation_rate,\r\n",
        "                              conv_name_base=conv_name_base + '2a',\r\n",
        "                              bn_name_base=bn_name_base + '2a')(input_feature)\r\n",
        "\r\n",
        "        if dropout is not None:\r\n",
        "            x = Dropout(dropout)(x)\r\n",
        "\r\n",
        "        x = residual_unit(filters=filters, kernel_size=(3, 3),\r\n",
        "                          conv_name_base=conv_name_base + '2b',\r\n",
        "                          bn_name_base=bn_name_base + '2b')(x)\r\n",
        "\r\n",
        "        if dropout is not None:\r\n",
        "            x = Dropout(dropout)(x)\r\n",
        "\r\n",
        "        x = residual_unit(filters=filters * 4, kernel_size=(1, 1),\r\n",
        "                          conv_name_base=conv_name_base + '2c',\r\n",
        "                          bn_name_base=bn_name_base + '2c')(x)\r\n",
        "\r\n",
        "        return _shortcut(input_feature, x)\r\n",
        "\r\n",
        "    return f\r\n",
        "\r\n",
        "\r\n",
        "def _handle_dim_ordering():\r\n",
        "    global ROW_AXIS\r\n",
        "    global COL_AXIS\r\n",
        "    global CHANNEL_AXIS\r\n",
        "    if K.image_data_format() == 'channels_last':\r\n",
        "        ROW_AXIS = 1\r\n",
        "        COL_AXIS = 2\r\n",
        "        CHANNEL_AXIS = 3\r\n",
        "    else:\r\n",
        "        CHANNEL_AXIS = 1\r\n",
        "        ROW_AXIS = 2\r\n",
        "        COL_AXIS = 3\r\n",
        "\r\n",
        "\r\n",
        "def _string_to_function(identifier):\r\n",
        "    if isinstance(identifier, six.string_types):\r\n",
        "        res = globals().get(identifier)\r\n",
        "        if not res:\r\n",
        "            raise ValueError('Invalid {}'.format(identifier))\r\n",
        "        return res\r\n",
        "    return identifier\r\n",
        "\r\n",
        "\r\n",
        "def ResNet(input_shape=None, classes=10, block='bottleneck', residual_unit='v2',\r\n",
        "           repetitions=None, initial_filters=64, activation='softmax', include_top=True,\r\n",
        "           input_tensor=None, dropout=None, transition_dilation_rate=(1, 1),\r\n",
        "           initial_strides=(2, 2), initial_kernel_size=(7, 7), initial_pooling='max',\r\n",
        "           final_pooling=None, top='classification'):\r\n",
        "    \"\"\"Builds a custom ResNet like architecture. Defaults to ResNet50 v2.\r\n",
        "    Args:\r\n",
        "        input_shape: optional shape tuple, only to be specified\r\n",
        "            if `include_top` is False (otherwise the input shape\r\n",
        "            has to be `(224, 224, 3)` (with `channels_last` dim ordering)\r\n",
        "            or `(3, 224, 224)` (with `channels_first` dim ordering).\r\n",
        "            It should have exactly 3 dimensions,\r\n",
        "            and width and height should be no smaller than 8.\r\n",
        "            E.g. `(224, 224, 3)` would be one valid value.\r\n",
        "        classes: The number of outputs at final softmax layer\r\n",
        "        block: The block function to use. This is either `'basic'` or `'bottleneck'`.\r\n",
        "            The original paper used `basic` for layers < 50.\r\n",
        "        repetitions: Number of repetitions of various block units.\r\n",
        "            At each block unit, the number of filters are doubled and the input size\r\n",
        "            is halved. Default of None implies the ResNet50v2 values of [3, 4, 6, 3].\r\n",
        "        residual_unit: the basic residual unit, 'v1' for conv bn relu, 'v2' for bn relu\r\n",
        "            conv. See [Identity Mappings in\r\n",
        "            Deep Residual Networks](https://arxiv.org/abs/1603.05027)\r\n",
        "            for details.\r\n",
        "        dropout: None for no dropout, otherwise rate of dropout from 0 to 1.\r\n",
        "            Based on [Wide Residual Networks.(https://arxiv.org/pdf/1605.07146) paper.\r\n",
        "        transition_dilation_rate: Dilation rate for transition layers. For semantic\r\n",
        "            segmentation of images use a dilation rate of (2, 2).\r\n",
        "        initial_strides: Stride of the very first residual unit and MaxPooling2D call,\r\n",
        "            with default (2, 2), set to (1, 1) for small images like cifar.\r\n",
        "        initial_kernel_size: kernel size of the very first convolution, (7, 7) for\r\n",
        "            imagenet and (3, 3) for small image datasets like tiny imagenet and cifar.\r\n",
        "            See [ResNeXt](https://arxiv.org/abs/1611.05431) paper for details.\r\n",
        "        initial_pooling: Determine if there will be an initial pooling layer,\r\n",
        "            'max' for imagenet and None for small image datasets.\r\n",
        "            See [ResNeXt](https://arxiv.org/abs/1611.05431) paper for details.\r\n",
        "        final_pooling: Optional pooling mode for feature extraction at the final\r\n",
        "            model layer when `include_top` is `False`.\r\n",
        "            - `None` means that the output of the model\r\n",
        "                will be the 4D tensor output of the\r\n",
        "                last convolutional layer.\r\n",
        "            - `avg` means that global average pooling\r\n",
        "                will be applied to the output of the\r\n",
        "                last convolutional layer, and thus\r\n",
        "                the output of the model will be a\r\n",
        "                2D tensor.\r\n",
        "            - `max` means that global max pooling will\r\n",
        "                be applied.\r\n",
        "        top: Defines final layers to evaluate based on a specific problem type. Options\r\n",
        "            are 'classification' for ImageNet style problems, 'segmentation' for\r\n",
        "            problems like the Pascal VOC dataset, and None to exclude these layers\r\n",
        "            entirely.\r\n",
        "    Returns:\r\n",
        "        The keras `Model`.\r\n",
        "    \"\"\"\r\n",
        "    if activation not in ['softmax', 'sigmoid', None]:\r\n",
        "        raise ValueError('activation must be one of \"softmax\", \"sigmoid\", or None')\r\n",
        "    if activation == 'sigmoid' and classes != 1:\r\n",
        "        raise ValueError('sigmoid activation can only be used when classes = 1')\r\n",
        "    if repetitions is None:\r\n",
        "        repetitions = [3, 4, 6, 3]\r\n",
        "    # Determine proper input shape\r\n",
        "    input_shape = _obtain_input_shape(input_shape,\r\n",
        "                                      default_size=32,\r\n",
        "                                      min_size=8,\r\n",
        "                                      data_format=K.image_data_format(),\r\n",
        "                                      require_flatten=include_top)\r\n",
        "    _handle_dim_ordering()\r\n",
        "    if len(input_shape) != 3:\r\n",
        "        raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\r\n",
        "\r\n",
        "    if block == 'basic':\r\n",
        "        block_fn = basic_block\r\n",
        "    elif block == 'bottleneck':\r\n",
        "        block_fn = bottleneck\r\n",
        "    elif isinstance(block, six.string_types):\r\n",
        "        block_fn = _string_to_function(block)\r\n",
        "    else:\r\n",
        "        block_fn = block\r\n",
        "\r\n",
        "    if residual_unit == 'v2':\r\n",
        "        residual_unit = _bn_relu_conv\r\n",
        "    elif residual_unit == 'v1':\r\n",
        "        residual_unit = _conv_bn_relu\r\n",
        "    elif isinstance(residual_unit, six.string_types):\r\n",
        "        residual_unit = _string_to_function(residual_unit)\r\n",
        "    else:\r\n",
        "        residual_unit = residual_unit\r\n",
        "\r\n",
        "    # Permute dimension order if necessary\r\n",
        "    if K.image_data_format() == 'channels_first':\r\n",
        "        input_shape = (input_shape[1], input_shape[2], input_shape[0])\r\n",
        "    # Determine proper input shape\r\n",
        "    input_shape = _obtain_input_shape(input_shape,\r\n",
        "                                      default_size=32,\r\n",
        "                                      min_size=8,\r\n",
        "                                      data_format=K.image_data_format(),\r\n",
        "                                      require_flatten=include_top)\r\n",
        "\r\n",
        "    img_input = Input(shape=input_shape, tensor=input_tensor)\r\n",
        "    x = _conv_bn_relu(filters=initial_filters, kernel_size=initial_kernel_size,\r\n",
        "                      strides=initial_strides)(img_input)\r\n",
        "    if initial_pooling == 'max':\r\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=initial_strides, padding=\"same\")(x)\r\n",
        "\r\n",
        "    block = x\r\n",
        "    filters = initial_filters\r\n",
        "    for i, r in enumerate(repetitions):\r\n",
        "        transition_dilation_rates = [transition_dilation_rate] * r\r\n",
        "        transition_strides = [(1, 1)] * r\r\n",
        "        if transition_dilation_rate == (1, 1):\r\n",
        "            transition_strides[0] = (2, 2)\r\n",
        "        block = _residual_block(block_fn, filters=filters,\r\n",
        "                                stage=i, blocks=r,\r\n",
        "                                is_first_layer=(i == 0),\r\n",
        "                                dropout=dropout,\r\n",
        "                                transition_dilation_rates=transition_dilation_rates,\r\n",
        "                                transition_strides=transition_strides,\r\n",
        "                                residual_unit=residual_unit)(block)\r\n",
        "        filters *= 2\r\n",
        "\r\n",
        "    # Last activation\r\n",
        "    x = _bn_relu(block)\r\n",
        "\r\n",
        "    # Classifier block\r\n",
        "    if include_top and top is 'classification':\r\n",
        "        x = GlobalAveragePooling2D()(x)\r\n",
        "        x = Dense(units=classes, activation=activation,\r\n",
        "                  kernel_initializer=\"he_normal\")(x)\r\n",
        "    elif include_top and top is 'segmentation':\r\n",
        "        x = Conv2D(classes, (1, 1), activation='linear', padding='same')(x)\r\n",
        "\r\n",
        "        if K.image_data_format() == 'channels_first':\r\n",
        "            channel, row, col = input_shape\r\n",
        "        else:\r\n",
        "            row, col, channel = input_shape\r\n",
        "\r\n",
        "        x = Reshape((row * col, classes))(x)\r\n",
        "        x = Activation(activation)(x)\r\n",
        "        x = Reshape((row, col, classes))(x)\r\n",
        "    elif final_pooling == 'avg':\r\n",
        "        x = GlobalAveragePooling2D()(x)\r\n",
        "    elif final_pooling == 'max':\r\n",
        "        x = GlobalMaxPooling2D()(x)\r\n",
        "\r\n",
        "    model = Model(inputs=img_input, outputs=x)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def ResNet34(input_shape, classes):\r\n",
        "    \"\"\"ResNet with 34 layers and v2 residual units\r\n",
        "    \"\"\"\r\n",
        "    return ResNet(input_shape, classes, basic_block, repetitions=[3, 4, 6, 3])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKG9brQpvLpm"
      },
      "source": [
        "img_width, img_height = 500, 500\r\n",
        "\r\n",
        "train_data_dir = 'train'\r\n",
        "validation_data_dir = 'validation'\r\n",
        "nb_train_samples = 1000\r\n",
        "nb_validation_samples = 160\r\n",
        "epochs = 12 #20\r\n",
        "batch_size = 20\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    input_shape = (3, img_width, img_height)\r\n",
        "else:\r\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRjWRBJSnZ3_",
        "outputId": "68a91136-ee37-497d-ba6c-e2ca53364262"
      },
      "source": [
        "model = ResNet34(input_shape, len(classes))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\r\n",
        "                                    shear_range=0.2,\r\n",
        "                                    zoom_range=0.2,\r\n",
        "                                    horizontal_flip=True)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    train_data_dir,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    batch_size=batch_size,\r\n",
        "    class_mode='categorical')\r\n",
        "\r\n",
        "validation_generator = test_datagen.flow_from_directory(\r\n",
        "    validation_data_dir,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    batch_size=batch_size,\r\n",
        "    class_mode='categorical')\r\n",
        "\r\n",
        "model.fit(\r\n",
        "    train_generator,\r\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\r\n",
        "    epochs=epochs,\r\n",
        "    validation_data=validation_generator,\r\n",
        "    validation_steps=nb_validation_samples // batch_size\r\n",
        "    )\r\n",
        "\r\n",
        "model.save_weights('model.h6')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reshaping via a convolution...\n",
            "reshaping via a convolution...\n",
            "reshaping via a convolution...\n",
            "reshaping via a convolution...\n",
            "Found 1100 images belonging to 3 classes.\n",
            "Found 161 images belonging to 3 classes.\n",
            "Epoch 1/12\n",
            "50/50 [==============================] - 750s 15s/step - loss: 2.2118 - accuracy: 0.8490 - val_loss: 2090.9578 - val_accuracy: 0.1625\n",
            "Epoch 2/12\n",
            "50/50 [==============================] - 747s 15s/step - loss: 1.9745 - accuracy: 0.8980 - val_loss: 41.7401 - val_accuracy: 0.4688\n",
            "Epoch 3/12\n",
            "50/50 [==============================] - 749s 15s/step - loss: 1.8104 - accuracy: 0.9230 - val_loss: 8.1032 - val_accuracy: 0.3500\n",
            "Epoch 4/12\n",
            "50/50 [==============================] - 748s 15s/step - loss: 1.7167 - accuracy: 0.9220 - val_loss: 2.0789 - val_accuracy: 0.8250\n",
            "Epoch 5/12\n",
            "50/50 [==============================] - 748s 15s/step - loss: 1.5989 - accuracy: 0.9260 - val_loss: 1.6371 - val_accuracy: 0.8750\n",
            "Epoch 6/12\n",
            "50/50 [==============================] - 747s 15s/step - loss: 1.4694 - accuracy: 0.9390 - val_loss: 6.4949 - val_accuracy: 0.4812\n",
            "Epoch 7/12\n",
            "50/50 [==============================] - 748s 15s/step - loss: 1.3595 - accuracy: 0.9390 - val_loss: 4.8723 - val_accuracy: 0.6687\n",
            "Epoch 8/12\n",
            "50/50 [==============================] - 747s 15s/step - loss: 1.2799 - accuracy: 0.9300 - val_loss: 1.7243 - val_accuracy: 0.8125\n",
            "Epoch 9/12\n",
            "50/50 [==============================] - 747s 15s/step - loss: 1.1723 - accuracy: 0.9390 - val_loss: 12.8384 - val_accuracy: 0.4187\n",
            "Epoch 10/12\n",
            "50/50 [==============================] - 744s 15s/step - loss: 1.0375 - accuracy: 0.9530 - val_loss: 1.8279 - val_accuracy: 0.7375\n",
            "Epoch 11/12\n",
            "50/50 [==============================] - 746s 15s/step - loss: 1.0127 - accuracy: 0.9330 - val_loss: 2.5598 - val_accuracy: 0.6250\n",
            "Epoch 12/12\n",
            "50/50 [==============================] - 744s 15s/step - loss: 0.9380 - accuracy: 0.9450 - val_loss: 2.0410 - val_accuracy: 0.6562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK2nImEJuq-g"
      },
      "source": [
        "## Prediction siit maalt edasi"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSP4l_h4uqGZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1fc1699-3cc7-406f-87ae-b77f1976f9d9"
      },
      "source": [
        "\"\"\"model = make_model_0()\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.load_weights('model.h5')\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"model = make_model_0()\\n\\nmodel.compile(loss='categorical_crossentropy',\\n              optimizer='adam',\\n              metrics=['accuracy'])\\nmodel.load_weights('model.h5')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoWyo3wPOb5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d488f3-1d7c-48e5-d3d3-d21ed5bc8402"
      },
      "source": [
        "# interior\r\n",
        "# img = urlretrieve(\"https://cache.kv.ee/iv2/obj/1_4_66885443.jpg\", \"doc111.jpg\")\r\n",
        "\r\n",
        "# ext\r\n",
        "img = urlretrieve(\"https://cache.kv.ee/iv2/obj/1_35_64066734.jpg\", \"doc111.jpg\")\r\n",
        "\r\n",
        "\r\n",
        "# doc \r\n",
        "# img = urlretrieve(\"https://www.wada-ama.org/sites/default/files/resources/thumbnails/tdssa_2017_eng_page_01.jpg\", \"doc111.jpg\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "img = image.load_img('doc111.jpg', target_size = (img_width, img_height))\r\n",
        "img = image.img_to_array(img)\r\n",
        "img = np.expand_dims(img, axis = 0)\r\n",
        "\r\n",
        "# arvamus = model.predict_classes(img)\r\n",
        "print(train_generator.class_indices)\r\n",
        "arvamus = np.argmax(model.predict(img), axis=-1)\r\n",
        "print(arvamus[0])\r\n",
        "protsent = model.predict(img)\r\n",
        "print(protsent[0])\r\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'document0': 0, 'facade0': 1, 'interior0': 2}\n",
            "0\n",
            "[1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98NQLvcJ8q3"
      },
      "source": [
        "# true_classes = []\r\n",
        "# predicted_classes = []\r\n",
        "\r\n",
        "# classes = ['document0','facade0','interior0']\r\n",
        "\r\n",
        "# for i in os.listdir('validation/facade0'):\r\n",
        "#   img = image.load_img('validation/facade0/'+i, target_size = (img_width, img_height))\r\n",
        "#   img = image.img_to_array(img)\r\n",
        "#   img = np.expand_dims(img, axis = 0)\r\n",
        "\r\n",
        "#   pred_i = np.argmax(model.predict(img), axis=-1)\r\n",
        "#   predicted_classes.append(classes[pred_i[0]])\r\n",
        "#   predicted_classes.append(pred_i[0])\r\n",
        "#   true_classes.append('facade0')\r\n",
        "  \r\n",
        "\r\n",
        "# for i in os.listdir('validation/document0'):\r\n",
        "#   img = image.load_img('validation/document0/'+i, target_size = (img_width, img_height))\r\n",
        "#   img = image.img_to_array(img)\r\n",
        "#   img = np.expand_dims(img, axis = 0)\r\n",
        "\r\n",
        "#   pred_i = np.argmax(model.predict(img), axis=-1)\r\n",
        "#   # predicted_classes.append(classes[pred_i[0]])\r\n",
        "#   predicted_classes.append(pred_i[0])\r\n",
        "#   true_classes.append('document0')\r\n",
        "\r\n",
        "\r\n",
        "# for i in os.listdir('validation/interior0'):\r\n",
        "#   img = image.load_img('validation/interior0/'+i, target_size = (img_width, img_height))\r\n",
        "#   img = image.img_to_array(img)\r\n",
        "#   img = np.expand_dims(img, axis = 0)\r\n",
        "\r\n",
        "#   pred_i = np.argmax(model.predict(img), axis=-1)\r\n",
        "#   # predicted_classes.append(classes[pred_i[0]])\r\n",
        "#   predicted_classes.append(pred_i[0])\r\n",
        "#   true_classes.append('interior0')\r\n",
        "\r\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EW-rNudJ8uM"
      },
      "source": [
        "# import sklearn.metrics as metrics\r\n",
        "# report = metrics.classification_report(true_classes, predicted_classes)\r\n",
        "# print(report)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CclbemFJSOCN"
      },
      "source": [
        "# from sklearn.metrics import classification_report\r\n",
        "# from sklearn.metrics import confusion_matrix\r\n",
        "# print(confusion_matrix(validation_generator.classes, predicted_classes))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSbuE4NsTvkC",
        "outputId": "6818ca8c-e820-4377-e382-318ea749c313"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // \r\n",
        "batch_size+1)\r\n",
        "y_pred = np.argmax(Y_pred, axis=1)\r\n",
        "print('Confusion Matrix')\r\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\r\n",
        "# print('Classification Report')\r\n",
        "# target_names = ['Cats', 'Dogs']\r\n",
        "# print(classification_report(validation_generator.classes, y_pred,  target_names=target_names))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 3 16  7]\n",
            " [ 5 50  7]\n",
            " [13 52  8]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}